import pandas as pd
import torch
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from tqdm import tqdm

# -----------------------------
# Device
# -----------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# -----------------------------
# Load Dataset
# -----------------------------
from sklearn.model_selection import train_test_split

# -----------------------------
# Load full dataset
# -----------------------------
df = pd.read_csv("/kaggle/input/disease-symptom-description-dataset/dataset.csv")

# -----------------------------
# Train / Test split
# -----------------------------
train_df, test_df = train_test_split(
    df,
    test_size=0.2,
    random_state=42,
    stratify=df["Disease"]   # important for multi-class balance
)
# -----------------------------
# Symptom columns
# -----------------------------
symptom_cols = [f"Symptom_{i}" for i in range(1, 18)]

# -----------------------------
# Combine symptoms into one sentence per row
# -----------------------------
def combine_symptoms(df):
    return df[symptom_cols].fillna("").apply(
        lambda row: " ".join(row.values.astype(str)), axis=1
    ).tolist()

X_train_text = combine_symptoms(train_df)
X_test_text  = combine_symptoms(test_df)

y_train = train_df["Disease"]
y_test  = test_df["Disease"]

# -----------------------------
# Encode labels
# -----------------------------
label_encoder = LabelEncoder()
y_train_enc = label_encoder.fit_transform(y_train)
y_test_enc  = label_encoder.transform(y_test)

# -----------------------------
# Load SentenceTransformer
# -----------------------------
model_name = "emilyalsentzer/Bio_ClinicalBERT"
sentence_model = SentenceTransformer(model_name, device=device)

# -----------------------------
# Generate Sentence Embeddings
# -----------------------------
def sentence_embeddings(texts, batch_size=64):
    embeddings = []
    for i in tqdm(range(0, len(texts), batch_size), desc="Embedding"):
        batch_texts = texts[i:i + batch_size]
        emb = sentence_model.encode(
            batch_texts,
            convert_to_numpy=True,
            show_progress_bar=False
        )
        embeddings.append(emb)
    return np.vstack(embeddings)

X_train_emb = sentence_embeddings(X_train_text)
X_test_emb  = sentence_embeddings(X_test_text)

print("Train embeddings:", X_train_emb.shape)
print("Test embeddings :", X_test_emb.shape)


clf = LogisticRegression(
    max_iter=1000,
    n_jobs=-1,
    multi_class="auto"
)

clf.fit(X_train_emb, y_train_enc)

# -----------------------------
# Evaluation
# -----------------------------
y_pred = clf.predict(X_test_emb)
accuracy = accuracy_score(y_test_enc, y_pred)

print("Accuracy:", accuracy)



# -----------------------------
# Sample patient symptom inputs
# -----------------------------
sample_data = [
    {
        "Symptom_1": "fever",
        "Symptom_2": "cough",
        "Symptom_3": "shortness of breath",
        "Symptom_4": "chest pain",
        "Symptom_5": "fatigue",
        "Symptom_6": "",
        "Symptom_7": "",
        "Symptom_8": "",
        "Symptom_9": "",
        "Symptom_10": "",
        "Symptom_11": "",
        "Symptom_12": "",
        "Symptom_13": "",
        "Symptom_14": "",
        "Symptom_15": "",
        "Symptom_16": "",
        "Symptom_17": ""
    },
    {
        "Symptom_1": "skin_rash",
        "Symptom_2": "nodal_skin_eruptions",
        "Symptom_3": "dischromic _patches",
        "Symptom_4": "",
        "Symptom_5": "",
        "Symptom_6": "",
        "Symptom_7": "",
        "Symptom_8": "",
        "Symptom_9": "",
        "Symptom_10": "",
        "Symptom_11": "",
        "Symptom_12": "",
        "Symptom_13": "",
        "Symptom_14": "",
        "Symptom_15": "",
        "Symptom_16": "",
        "Symptom_17": ""
    },
    {
        "Symptom_1": "headache",
        "Symptom_2": "dizziness",
        "Symptom_3": "confusion",
        "Symptom_4": "blurred vision",
        "Symptom_5": "nausea",
        "Symptom_6": "",
        "Symptom_7": "",
        "Symptom_8": "",
        "Symptom_9": "",
        "Symptom_10": "",
        "Symptom_11": "",
        "Symptom_12": "",
        "Symptom_13": "",
        "Symptom_14": "",
        "Symptom_15": "",
        "Symptom_16": "",
        "Symptom_17": ""
    }
]

sample_df = pd.DataFrame(sample_data)

symptom_cols = [f"Symptom_{i}" for i in range(1, 18)]

def combine_symptoms_df(df):
    return df[symptom_cols].fillna("").apply(
        lambda row: " ".join(row.values.astype(str)),
        axis=1
    ).tolist()

sample_texts = combine_symptoms_df(sample_df)

for i, text in enumerate(sample_texts, 1):
    print(f"\nSample {i} text:")
    print(text)

sample_embeddings = sentence_model.encode(
    sample_texts,
    convert_to_numpy=True,
    show_progress_bar=False
)

print("Sample embeddings shape:", sample_embeddings.shape)



probs = clf.predict_proba(sample_embeddings)

for i, prob in enumerate(probs, 1):
    top_idx = np.argmax(prob)
    top_disease = label_encoder.inverse_transform([top_idx])[0]
    confidence = prob[top_idx]
    print(f"Sample {i}: {top_disease} (confidence = {confidence:.2f})")



# Predict encoded labels
pred_enc = clf.predict(sample_embeddings)

# Convert back to disease names
pred_diseases = label_encoder.inverse_transform(pred_enc)

# Display results
for i, disease in enumerate(pred_diseases, 1):
    print(f"üßë‚Äç‚öïÔ∏è Sample {i} ‚Üí Predicted Disease: {disease}")
