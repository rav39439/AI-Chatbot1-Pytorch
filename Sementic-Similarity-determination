import os
from typing import List
from tqdm import tqdm

def chunk_text(
    text: str,
    chunk_size: int = 500,
    overlap: int = 50
) -> List[str]:
    """
    Splits text into overlapping chunks.
    """
    words = text.split()
    chunks = []

    start = 0
    while start < len(words):
        end = start + chunk_size
        chunk = words[start:end]
        chunks.append(" ".join(chunk))
        start = end - overlap

    return chunks



# def load_passages(folder_path: str):
#     passages = {}
#     for filename in os.listdir(folder_path):
#         if filename.endswith(".txt"):
#             path = os.path.join(folder_path, filename)
#             with open(path, "r", encoding="utf-8") as f:
#                 passages[filename] = f.read()
#     return passages


import os
import pandas as pd

def load_passages(folder_path: str):
    """
    Loads passages from CSV files.
    Each row in column 'passages' is treated as one passage.
    """
    passages = {}

    for filename in os.listdir(folder_path):
        if filename.endswith(".csv"):
            path = os.path.join(folder_path, filename)
            df = pd.read_csv(path)

            if "text" not in df.columns:
                raise ValueError(f"'passages' column not found in {filename}")

            for idx, text in enumerate(df["text"].dropna()):
                key = f"{filename}_row_{idx}"
                passages[key] = str(text)

    return passages


from sentence_transformers import SentenceTransformer
import numpy as np
from tqdm import tqdm

model = SentenceTransformer("all-MiniLM-L6-v2")



def embed_passage_chunks(passages: dict):
    """
    Returns:
    {
      passage_name: [chunk_embedding_1, chunk_embedding_2, ...]
    }
    """
    passage_chunk_embeddings = {}

    for name, text in tqdm(passages.items(), desc="Embedding passages"):
        chunks = chunk_text(text)
        embeddings = model.encode(
            chunks,
            batch_size=32,
            show_progress_bar=False,
            normalize_embeddings=True
        )
        passage_chunk_embeddings[name] = embeddings

    return passage_chunk_embeddings



def aggregate_embeddings(passage_chunk_embeddings: dict):
    """
    Returns:
    {
      passage_name: passage_embedding
    }
    """
    passage_embeddings = {}

    for name, embeddings in passage_chunk_embeddings.items():
        passage_embeddings[name] = np.mean(embeddings, axis=0)

    return passage_embeddings



if __name__ == "__main__":
    PASSAGE_DIR = "/kaggle/input/cefr-levelled-english-texts"

    # Step 1: Load passages
    passages = load_passages(PASSAGE_DIR)
    

    # Step 2: Chunk + embed
    passage_chunk_embeddings = embed_passage_chunks(passages)

    # Step 3: Aggregate
    passage_embeddings = aggregate_embeddings(passage_chunk_embeddings)

    print(f"Processed {len(passage_embeddings)} passages.")


def embed_query(query: str, model):
    """
    Returns normalized query embedding.
    """
    embedding = model.encode(
        query,
        normalize_embeddings=True
    )
    return embedding


def apply_temperature(similarities: dict, temperature: float = 0.1):
    """
    Scales similarity scores before softmax.
    """
    return {
        pid: score / temperature
        for pid, score in similarities.items()
    }


import numpy as np

def compute_similarities(query_embedding, passage_embeddings: dict):
    """
    Returns:
    {
      passage_id: cosine_similarity
    }
    """
    similarities = {}

    for pid, p_embedding in passage_embeddings.items():
        similarities[pid] = float(np.dot(query_embedding, p_embedding))

    return similarities



from scipy.special import softmax

def softmax_probabilities(similarities: dict):
    """
    Converts similarity scores into probabilities.
    """
    ids = list(similarities.keys())
    scores = np.array(list(similarities.values()))

    probs = softmax(scores)

    return dict(zip(ids, probs))


def rank_passages(probabilities: dict, top_k: int = None):
    """
    Returns sorted (passage_id, probability).
    """
    ranked = sorted(
        probabilities.items(),
        key=lambda x: x[1],
        reverse=True
    )

    return ranked[:top_k] if top_k else ranked


from sentence_transformers import SentenceTransformer

if __name__ == "__main__":
    PASSAGE_DIR = "/kaggle/input/cefr-levelled-english-texts"
    QUERY = "Valentine's Day, February 14, is a holiday that celebrates love and friendship in the United States"

    # Load model
    model = SentenceTransformer("all-MiniLM-L6-v2")

    # STEP 1: Load passages from CSV
    passages = load_passages(PASSAGE_DIR)

    # STEP 2: Chunk + embed passage chunks
    passage_chunk_embeddings = embed_passage_chunks(passages)

    # STEP 3: Aggregate embeddings
    passage_embeddings = aggregate_embeddings(passage_chunk_embeddings)

    # STEP 4: Embed query
    query_embedding = embed_query(QUERY, model)

    # STEP 5: Similarity computation
    similarities = compute_similarities(
        query_embedding,
        passage_embeddings
    )

    # STEP 6: Temperature scaling
    scaled_similarities = apply_temperature(
        similarities,
        temperature=0.1
    )

    # STEP 7: Softmax probabilities
    probabilities = softmax_probabilities(scaled_similarities)

    # STEP 8: Rank results
    ranked_results = rank_passages(probabilities)

    # Display results
    for pid, prob in ranked_results:
        print(f"{pid}: {prob:.4f}")



